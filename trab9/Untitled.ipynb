{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gera_obvs(k, m):\n",
    "    print('teste')\n",
    "    semente = np.array([[1]])\n",
    "    obvs = []\n",
    "    for i in range(k):\n",
    "        aux_obv = []\n",
    "        for j in range(2**i):\n",
    "            comb1 = np.array(np.concatenate((semente[j], semente[j])))\n",
    "            comb2 = np.array(np.concatenate((semente[j], -1*semente[j])))\n",
    "            aux_obv.append(np.array(comb1))\n",
    "            aux_obv.append(np.array(comb2))\n",
    "        semente = aux_obv\n",
    "        obvs = aux_obv\n",
    "    return obvs[0:10]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gera_obvs(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.ceil(4.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if (self.ciclos == 0) and (i == 0):\n",
    "                    pesos_ci1_saida_anterior = self.pesos_ci1_saida\n",
    "                    bias_saida_anterior = self.bias_saida\n",
    "                    pesos_ini_ci1_anterior = self.pesos_ini_ci1\n",
    "                    bias_c1_anterior = self.bias_c1\n",
    "                    #Correção dos pesos da camada intermediária para camada de saída e bias da camada de saída\n",
    "                    self.pesos_ci1_saida = self.pesos_ci1_saida + delta_pesos_ci1_saida.T \n",
    "                    self.bias_saida = self.bias_saida + delta_bias_saida.T\n",
    "                    #Correção dos pesos da camada intermediária para camada de saída e bias da camada de intermediária\n",
    "                    self.pesos_ini_ci1 = self.pesos_ini_ci1 + delta_pesos_ini_ci1.T\n",
    "                    self.bias_c1 = self.bias_c1 + delta_bias_c1\n",
    "                else:\n",
    "                    const_momentum = random.uniform(0.15, 0.75)\n",
    "                    termo_momentum = const_momentum * (self.pesos_ci1_saida - pesos_ci1_saida_anterior)\n",
    "                    pesos_ci1_saida_anterior = self.pesos_ci1_saida\n",
    "                    self.pesos_ci1_saida = self.pesos_ci1_saida + delta_pesos_ci1_saida.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.bias_saida - bias_saida_anterior)\n",
    "                    bias_saida_anterior = self.bias_saida\n",
    "                    self.bias_saida = self.bias_saida + delta_bias_saida.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.pesos_ini_ci1 - pesos_ini_ci1_anterior)\n",
    "                    pesos_ini_ci1_anterior = self.pesos_ini_ci1\n",
    "                    self.pesos_ini_ci1 = self.pesos_ini_ci1 + delta_pesos_ini_ci1.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.bias_c1 - bias_c1_anterior)\n",
    "                    bias_c1_anterior = self.bias_c1\n",
    "                    self.bias_c1 = self.bias_c1 + delta_bias_c1 + termo_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Taxa de aprendizagem:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68cd8703d514aea9aa00c34258cf56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.01, continuous_update=False, max=1.0, min=0.01, readout_format='.3f', step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantidade de neurônios da camada intermediária:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8529ec128a443bebd30fadad4a44e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=20, continuous_update=False, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantidade de amostras:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425160b8dca94710b5f74cc052f94af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=50, continuous_update=False, max=1000, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Critério de parada:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f4346afa2247f3aecb9c86a4085f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Erro', 'Ciclos'), style=DescriptionStyle(description_width='initial'), value='Erro')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Número de ciclos:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7660cafce9024760972578f858b2e24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, max=1000, min=1, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Erro tolerado:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962ee3f80924475f90e9adc96dffc9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.1, continuous_update=False, max=1.0, readout_format='.5f', step=0.001, style=SliderStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbb3ca0bd4f4f948322ed10d4cd9ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Treinar a rede', style=ButtonStyle()), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter, LogLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from math import cos, tanh\n",
    "from time import sleep\n",
    "\n",
    "from ipywidgets import *\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "########## entradas dos parametros ##########\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "print('\\n\\nTaxa de aprendizagem:')\n",
    "taxa_aprendizagem = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0.01,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.3f',\n",
    ")\n",
    "display(taxa_aprendizagem)\n",
    "\n",
    "print('\\n\\nQuantidade de neurônios da camada intermediária:')\n",
    "qnt_neuronios = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(qnt_neuronios)\n",
    "\n",
    "print('\\n\\nQuantidade de amostras:')\n",
    "qnt_amostras = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(qnt_amostras)\n",
    "\n",
    "print('\\n\\nCritério de parada:')\n",
    "parada = widgets.RadioButtons(\n",
    "    options=['Erro', 'Ciclos'],\n",
    "    disabled=False, style=style\n",
    ")\n",
    "display(parada)\n",
    "\n",
    "print('\\n\\nNúmero de ciclos:')\n",
    "ciclos = widgets.IntSlider(\n",
    "    value=10,min=1,max=1000,step=1,\n",
    "    continuous_update=False,\n",
    "    readout=True, style=style\n",
    ")\n",
    "display(ciclos)\n",
    "\n",
    "print('\\n\\nErro tolerado:')\n",
    "erro = widgets.FloatSlider(\n",
    "    value=0.1,min=0,max=1,step=0.001,\n",
    "    continuous_update=False,\n",
    "    readout=True, style=style,\n",
    "    readout_format='.5f',\n",
    ")\n",
    "display(erro)\n",
    "\n",
    "class RedeMLP():\n",
    "    def __init__(self, conjunto_entradas, targets, taxa_aprendizagem, parada, ciclos_max, \n",
    "                 erro_tolerado, qnt_neuronios, **kwargs):\n",
    "        self.numero_entradas = 256 #tamanho da imagem\n",
    "        self.numero_saidas = 10 #0-9\n",
    "        self.conjunto_entradas = np.array(conjunto_entradas)\n",
    "        self.targets = np.array(targets)\n",
    "        self.taxa_aprendizagem = taxa_aprendizagem\n",
    "        self.taxa_aprendizagem_inicial = taxa_aprendizagem\n",
    "        self.ciclos = 0\n",
    "        self.ciclos_max = ciclos_max\n",
    "        self.parada = parada\n",
    "        #Quantidade de neuronios seleciondos para camada intermediária\n",
    "        self.qnt_neuronios_intermediarios = qnt_neuronios\n",
    "        self.erro_tolerado = erro_tolerado\n",
    "        #Pesos das ligações entre as camadas inicial e intermediária; intermediária e saída\n",
    "        self.pesos_ini_inter, self.pesos_inter_saida = self.__inicializa_pesos()\n",
    "        #Iniciliza os bias da camada intermediária\n",
    "        self.bias_intermediario = np.asmatrix(np.array([random.uniform(-0.5,0.5) for saida in range(qnt_neuronios)]))\n",
    "        #Inicializa o bias da camada de saida\n",
    "        self.bias_saida = np.asmatrix(np.array([random.uniform(-0.5,0.5) for i in range(self.numero_saidas)]))\n",
    "        self.erro = 0\n",
    "        \n",
    "    def __inicializa_pesos(self):\n",
    "        pesos_ini_inter = []\n",
    "        pesos_inter_saida = []\n",
    "        \n",
    "        #mxn = onde m é o número de entradas e n é o número de neurônios da camada intermediária\n",
    "        for i in range(self.numero_entradas):\n",
    "            peso_aux = []\n",
    "            for j in range(self.qnt_neuronios_intermediarios):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_ini_inter.append(peso_aux)\n",
    "        \n",
    "        #nxk onde n é o número de neurônios da camada intermediária e k é o número de saídas\n",
    "        for i in range(self.qnt_neuronios_intermediarios):\n",
    "            peso_aux = []\n",
    "            for i in range(self.numero_saidas):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_inter_saida.append(peso_aux)\n",
    "            \n",
    "        #print(\"Tam peso ini_inter\", len(pesos_ini_inter[0]))\n",
    "        #print(\"Tam peso inter_saida\", len(pesos_inter_saida[0]))\n",
    "        return np.array(pesos_ini_inter), np.array(pesos_inter_saida)\n",
    "    \n",
    "    def __f_ativacao(self, matriz):\n",
    "        #print(\"ZIN\", zin)\n",
    "        out = []\n",
    "        dim = matriz.shape #dimensão da matriz\n",
    "        for i in range(dim[0]):\n",
    "            aux = []\n",
    "            for j in range(dim[1]):\n",
    "                aux.append(tanh(matriz.item(i,j)))\n",
    "            out.append(aux)\n",
    "                \n",
    "        return np.matrix(np.array(out))\n",
    "    \n",
    "    def __calcula_saida__(self, saida):\n",
    "        dists_euclidiana = []\n",
    "        for i in range(10):\n",
    "            calculo = np.sum(np.power(np.power((self.targets[i]-saida),2),0.5))\n",
    "            dists_euclidiana.append(calculo)\n",
    "        menor_valor = np.amin(dists_euclidiana)\n",
    "        id_menor_valor = dists_euclidiana.index(menor_valor)\n",
    "        return np.asmatrix(self.targets[id_menor_valor]);\n",
    "    \n",
    "    def __normaliza_saida__(self, saida):\n",
    "        saida[saida >= 0.5] = 1\n",
    "        saida[saida < 0.5] = 0\n",
    "        return saida\n",
    "        \n",
    "    \n",
    "    def treinamento(self):\n",
    "        print(\"#Parametros da função\")\n",
    "        treinada = False\n",
    "        erros = []\n",
    "        \n",
    "        while not treinada:\n",
    "            i = 0 \n",
    "            self.erro = 0\n",
    "            \n",
    "            for entrada_i in self.conjunto_entradas:\n",
    "                ####################Etapa de Forward#################################\n",
    "                ##############Camada inicial para intermediária\n",
    "                #resultado = 1xn, onde n é o número de neurônios da camada intermediária\n",
    "                \n",
    "                zin = (np.asmatrix(entrada_i) @ self.pesos_ini_inter) + self.bias_intermediario\n",
    "                z = self.__f_ativacao(zin)\n",
    "\n",
    "                ##############Camada intermediária para saída\n",
    "                yin = (z @ self.pesos_inter_saida) + self.bias_saida\n",
    "                y = self.__f_ativacao(yin)\n",
    "                #y = self.__calcula_saida__(y)\n",
    "                #print(\"y\", y)\n",
    "                \n",
    "                \n",
    "                #####################Etapa de backward\n",
    "                #Cálculo do erro\n",
    "                self.erro += 0.5 * np.sum(np.power((self.targets[i] - y), 2))\n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada intermediária para camada de saída\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                #np.multiply para se fazer uma multiplicação item por item\n",
    "                deltak = np.multiply((self.targets[i] - y).T,(1 + y).T)\n",
    "                deltak = np.multiply(deltak, (1 - y).T)\n",
    "                \n",
    "                \n",
    "                i+=1#ERRADO\n",
    "                \n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_inter_saida = deltak @ z\n",
    "                delta_pesos_inter_saida = self.taxa_aprendizagem * delta_pesos_inter_saida\n",
    "                \n",
    "                #Parâmetro para correção do bias\n",
    "                delta_bias_saida = np.multiply(self.taxa_aprendizagem, deltak)\n",
    "                \n",
    "                #print('delta pesos de saida: ', delta_pesos_inter_saida)\n",
    "                #print('delta bias de saida: ', delta_bias_saida)\n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada entrada para camada de intermediária\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                delta_in = deltak.T @ self.pesos_inter_saida.T\n",
    "                \n",
    "                \n",
    "                deltaj = np.multiply(delta_in, (1+z))\n",
    "                deltaj = np.multiply(deltaj, (1-z))\n",
    "                #print('delta_in: ', delta_in)\n",
    "                #print('deltaj: ', deltaj)\n",
    "                \n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_ini_inter = deltaj.T @ np.asmatrix(entrada_i)\n",
    "                delta_pesos_ini_inter = np.multiply(self.taxa_aprendizagem, delta_pesos_ini_inter)\n",
    "                \n",
    "                delta_bias_intermediario = np.multiply(self.taxa_aprendizagem, deltaj)\n",
    "                #print('delta pesos de intermediário: ', delta_pesos_ini_inter)\n",
    "                #print('delta bias de intermediário: ', delta_bias_intermediario)\n",
    "\n",
    "                #Correção dos pesos da camada intermediária para camada de saída e bias da camada de saída\n",
    "                self.pesos_inter_saida = self.pesos_inter_saida + delta_pesos_inter_saida.T\n",
    "                \n",
    "                self.bias_saida = (self.bias_saida + delta_bias_saida.T)\n",
    "                \n",
    "                #print(\"Pesos corrigidos da camada saída:\", self.pesos_inter_saida)\n",
    "                #print(\"bias corrigidos da camada saída:\", self.bias_saida)\n",
    "                \n",
    "                #Correção dos pesos da camada intermediária para camada de saída e bias da camada de intermediária\n",
    "                \n",
    "                self.pesos_ini_inter = self.pesos_ini_inter + delta_pesos_ini_inter.T\n",
    "                self.bias_intermediario = (self.bias_intermediario + delta_bias_intermediario)\n",
    "                #print(\"Pesos corrigidos da camada intermediária:\", self.pesos_ini_inter)\n",
    "                #print(\"bias corrigidos da camada intermediária:\", self.bias_intermediario)\n",
    "                \n",
    "                #Ajuste da taxa de aprendizagem\n",
    "            self.erro = (1/900)*self.erro\n",
    "            erros.append(self.erro)\n",
    "            print('erro', self.erro)\n",
    "            if (self.parada == 'ciclos' and self.ciclos >= self.ciclos_max) \\\n",
    "                or (self.parada == 'erro' and self.erro <= self.erro_tolerado):\n",
    "                #print('erro final: ', self.erro)\n",
    "                treinada = True\n",
    "            else:\n",
    "                self.ciclos += 1\n",
    "                \n",
    "        return list(range(0, self.ciclos+1)), erros\n",
    "    \n",
    "    def operacao(self, conjunto_testes):\n",
    "        acertos = 0\n",
    "        i = 0\n",
    "        for entrada_i in self.conjunto_entradas:\n",
    "            ####################Etapa de Forward#################################\n",
    "            ##############Camada inicial para intermediária\n",
    "            #resultado = 1xn, onde n é o número de neurônios da camada intermediária\n",
    "                \n",
    "            zin = (np.asmatrix(entrada_i) @ self.pesos_ini_inter) + self.bias_intermediario\n",
    "            z = self.__f_ativacao(zin)\n",
    "\n",
    "            ##############Camada intermediária para saída\n",
    "            yin = (z @ self.pesos_inter_saida) + self.bias_saida\n",
    "            y = self.__f_ativacao(yin)\n",
    "            print('yin0', y)\n",
    "            y = self.__normaliza_saida__(y)\n",
    "            #y = self.__calcula_saida__(y)\n",
    "            print('y', np.asmatrix(y))\n",
    "            print('t', np.asmatrix(self.targets[i]))\n",
    "            if(np.array_equal(np.asmatrix(y), np.asmatrix(self.targets[i]))):\n",
    "                acertos += 1\n",
    "            i+=1\n",
    "\n",
    "        return acertos\n",
    "\n",
    "##### definindo as entradas a partir do arquivo digitostreinamento900.txt #####\n",
    "def get_inputs_from_txt():\n",
    "    inputs = []\n",
    "    file = open('digitos/digitostreinamento900.txt', 'r')\n",
    "    for line in file :\n",
    "        line = line.split(\" \")\n",
    "        ipt = []\n",
    "        for element in line:\n",
    "            if element != \"\":\n",
    "                ipt.append(float(element))\n",
    "        inputs.append(ipt)\n",
    "    file.close()\n",
    "    return np.array(inputs)\n",
    "##############################################\n",
    "\n",
    "def get_obvs(k, m):\n",
    "    semente = np.array([[1]])\n",
    "    obvs = []\n",
    "    for i in range(k):\n",
    "        aux_obv = []\n",
    "        for j in range(2**i):\n",
    "            comb1 = np.array(np.concatenate((semente[j], semente[j])))\n",
    "            comb2 = np.array(np.concatenate((semente[j], -1*semente[j])))\n",
    "            aux_obv.append(np.array(comb1))\n",
    "            aux_obv.append(np.array(comb2))\n",
    "        semente = aux_obv\n",
    "        obvs = aux_obv\n",
    "        \n",
    "    targets = []\n",
    "    for i in range(90):\n",
    "        for j in range(10):\n",
    "            targets.append(obvs[j])\n",
    "        \n",
    "    return np.array(targets)\n",
    "\n",
    "def get_targets():\n",
    "    targets_aux = pd.read_csv('targets.csv').values\n",
    "    targets = []\n",
    "    for i in range(90):\n",
    "        for j in range(10):\n",
    "            targets.append(list(targets_aux[j]))\n",
    "        \n",
    "    return np.array(targets)\n",
    "\n",
    "def processar():\n",
    "    conjunto_entradas = get_inputs_from_txt()\n",
    "    #targets = get_obvs(4,1)\n",
    "    targets = get_targets()\n",
    "    #print(\"Conjunto de entradas:\", conjunto_entradas[0])\n",
    "    mlp = RedeMLP(\n",
    "        conjunto_entradas = conjunto_entradas, \n",
    "        targets = targets, \n",
    "        taxa_aprendizagem = taxa_aprendizagem.value,\n",
    "        parada = parada.value.lower(),\n",
    "        ciclos_max = ciclos.value,\n",
    "        erro_tolerado = erro.value,\n",
    "        qnt_neuronios = qnt_neuronios.value\n",
    "    )\n",
    "\n",
    "    #print(\"Entradas: \", mlp.conjunto_entradas)\n",
    "    lista_ciclos, lista_erros = mlp.treinamento() \n",
    "    acertos = mlp.operacao(conjunto_entradas)\n",
    "    print(acertos)\n",
    "    \n",
    "\n",
    "widgets.interact_manual.opts['manual_name'] = 'Treinar a rede' # muda texto do botao\n",
    "interact_manual(processar); # metodo a executar quando pressionar o botao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
