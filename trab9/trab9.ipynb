{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Multilayer Perceptron para reconhecimento de padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter, LogLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from math import cos, tanh\n",
    "from time import sleep\n",
    "\n",
    "from ipywidgets import *\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "########## entradas dos parametros ##########\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "print('\\n\\nTaxa de aprendizagem:')\n",
    "taxa_aprendizagem = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0.01,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.3f',\n",
    ")\n",
    "display(taxa_aprendizagem)\n",
    "\n",
    "print('\\n\\nQuantidade de neurônios da camada intermediária:')\n",
    "qnt_neuronios = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(qnt_neuronios)\n",
    "\n",
    "print('\\n\\nQuantidade de amostras:')\n",
    "qnt_amostras = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(qnt_amostras)\n",
    "\n",
    "print('\\n\\nCritério de parada:')\n",
    "parada = widgets.RadioButtons(\n",
    "    options=['Erro', 'Ciclos'],\n",
    "    disabled=False, style=style\n",
    ")\n",
    "display(parada)\n",
    "\n",
    "print('\\n\\nNúmero de ciclos:')\n",
    "ciclos = widgets.IntSlider(\n",
    "    value=10,min=1,max=1000,step=1,\n",
    "    continuous_update=False,\n",
    "    readout=True, style=style\n",
    ")\n",
    "display(ciclos)\n",
    "\n",
    "print('\\n\\nErro tolerado:')\n",
    "erro = widgets.FloatSlider(\n",
    "    value=0.1,min=0,max=1,step=0.001,\n",
    "    continuous_update=False,\n",
    "    readout=True, style=style,\n",
    "    readout_format='.5f',\n",
    ")\n",
    "display(erro)\n",
    "\n",
    "class RedeMLP():\n",
    "    def __init__(self, conjunto_entradas, targets, taxa_aprendizagem, parada, ciclos_max, \n",
    "                 erro_tolerado, qnt_neuronios, **kwargs):\n",
    "        self.numero_entradas = 256 #tamanho da imagem\n",
    "        self.numero_saidas = 10 #0-9\n",
    "        self.conjunto_entradas = np.array(conjunto_entradas)\n",
    "        self.targets = np.array(targets)\n",
    "        self.taxa_aprendizagem = taxa_aprendizagem\n",
    "        self.ciclos = 0\n",
    "        self.ciclos_max = ciclos_max\n",
    "        self.parada = parada\n",
    "        #Quantidade de neuronios seleciondos para camada intermediária\n",
    "        self.qnt_neuronios_intermediarios = qnt_neuronios\n",
    "        self.erro_tolerado = erro_tolerado\n",
    "        #Pesos das ligações entre as camadas inicial e intermediária; intermediária e saída\n",
    "        self.pesos_ini_inter, self.pesos_inter_saida = self.__inicializa_pesos()\n",
    "        #Iniciliza os bias da camada intermediária\n",
    "        self.bias_intermediario = np.asmatrix(np.array([random.uniform(-0.5,0.5) for saida in range(qnt_neuronios)]))\n",
    "        #Inicializa o bias da camada de saida\n",
    "        self.bias_saida = np.asmatrix(np.array([random.uniform(-0.5,0.5) for i in range(self.numero_saidas)]))\n",
    "        self.erro = 0\n",
    "        \n",
    "    def __inicializa_pesos(self):\n",
    "        pesos_ini_inter = []\n",
    "        pesos_inter_saida = []\n",
    "        \n",
    "        #mxn = onde m é o número de entradas e n é o número de neurônios da camada intermediária\n",
    "        for i in range(self.numero_entradas):\n",
    "            peso_aux = []\n",
    "            for j in range(self.qnt_neuronios_intermediarios):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_ini_inter.append(peso_aux)\n",
    "        \n",
    "        #nxk onde n é o número de neurônios da camada intermediária e k é o número de saídas\n",
    "        for i in range(self.qnt_neuronios_intermediarios):\n",
    "            peso_aux = []\n",
    "            for i in range(self.numero_saidas):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_inter_saida.append(peso_aux)\n",
    "            \n",
    "        #print(\"Tam peso ini_inter\", len(pesos_ini_inter[0]))\n",
    "        #print(\"Tam peso inter_saida\", len(pesos_inter_saida[0]))\n",
    "        return np.array(pesos_ini_inter), np.array(pesos_inter_saida)\n",
    "    \n",
    "    def __f_ativacao(self, matriz):\n",
    "        #print(\"ZIN\", zin)\n",
    "        out = []\n",
    "        dim = matriz.shape #dimensão da matriz\n",
    "        for i in range(dim[0]):\n",
    "            aux = []\n",
    "            for j in range(dim[1]):\n",
    "                aux.append(tanh(matriz.item(i,j)))\n",
    "            out.append(aux)\n",
    "                \n",
    "        return np.matrix(np.array(out))\n",
    "    \n",
    "    def treinamento(self):\n",
    "        print(\"#Parametros da função\")\n",
    "        treinada = False\n",
    "        erros = []\n",
    "        \n",
    "        while not treinada:\n",
    "            i = 0 \n",
    "            self.erro = 0\n",
    "            \n",
    "            for entrada_i in self.conjunto_entradas:\n",
    "                ####################Etapa de Forward#################################\n",
    "                ##############Camada inicial para intermediária\n",
    "                #resultado = 1xn, onde n é o número de neurônios da camada intermediária\n",
    "                \n",
    "                zin = (np.asmatrix(entrada_i) @ self.pesos_ini_inter) + self.bias_intermediario\n",
    "                z = self.__f_ativacao(zin)\n",
    "\n",
    "                ##############Camada intermediária para saída\n",
    "                yin = (z @ self.pesos_inter_saida) + self.bias_saida\n",
    "                y = self.__f_ativacao(yin)\n",
    "                #print(\"y\", y)\n",
    "                \n",
    "                \n",
    "                #####################Etapa de backward\n",
    "                #Cálculo do erro\n",
    "                self.erro += 0.5 * np.sum(np.power((self.targets[i] - y), 2))\n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada intermediária para camada de saída\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                #np.multiply para se fazer uma multiplicação item por item\n",
    "                deltak = np.multiply((self.targets[i] - y).T,(1 + y).T)\n",
    "                deltak = np.multiply(deltak, (1 - y).T)\n",
    "                \n",
    "                \n",
    "                i+=1#ERRADO\n",
    "                \n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_inter_saida = deltak @ z\n",
    "                delta_pesos_inter_saida = self.taxa_aprendizagem * delta_pesos_inter_saida\n",
    "                \n",
    "                #Parâmetro para correção do bias\n",
    "                delta_bias_saida = np.multiply(self.taxa_aprendizagem, deltak)\n",
    "                \n",
    "                #print('delta pesos de saida: ', delta_pesos_inter_saida)\n",
    "                #print('delta bias de saida: ', delta_bias_saida)\n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada entrada para camada de intermediária\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                delta_in = deltak.T @ self.pesos_inter_saida.T\n",
    "                \n",
    "                \n",
    "                deltaj = np.multiply(delta_in, (1+z))\n",
    "                deltaj = np.multiply(deltaj, (1-z))\n",
    "                #print('delta_in: ', delta_in)\n",
    "                #print('deltaj: ', deltaj)\n",
    "                print(deltaj.T)\n",
    "                input()\n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_ini_inter = deltaj.T@ entrada_i\n",
    "                delta_pesos_ini_inter = np.multiply(self.taxa_aprendizagem, deltaj.T)\n",
    "                delta_bias_intermediario = np.multiply(self.taxa_aprendizagem, deltaj)\n",
    "                #print('delta pesos de intermediário: ', delta_pesos_ini_inter)\n",
    "                #print('delta bias de intermediário: ', delta_bias_intermediario)\n",
    "\n",
    "                #Correção dos pesos da camada intermediária para camada de saída e bias da camada de saída\n",
    "                self.pesos_inter_saida = self.pesos_inter_saida + delta_pesos_inter_saida.T\n",
    "                self.bias_saida = (self.bias_saida + delta_bias_saida.T)[0]\n",
    "                #print(\"Pesos corrigidos da camada saída:\", self.pesos_inter_saida)\n",
    "                #print(\"bias corrigidos da camada saída:\", self.bias_saida)\n",
    "                \n",
    "                #Correção dos pesos da camada intermediária para camada de saída e bias da camada de intermediária\n",
    "                self.pesos_ini_inter = self.pesos_ini_inter + delta_pesos_ini_inter.T\n",
    "                \n",
    "                self.bias_intermediario = (self.bias_intermediario + delta_bias_intermediario)[0]\n",
    "                \n",
    "                #print(\"Pesos corrigidos da camada intermediária:\", self.pesos_ini_inter)\n",
    "                #print(\"bias corrigidos da camada intermediária:\", self.bias_intermediario)\n",
    "            erros.append(self.erro)\n",
    "            print(self.erro)\n",
    "            if (self.parada == 'ciclos' and self.ciclos >= self.ciclos_max) \\\n",
    "                or (self.parada == 'erro' and self.erro <= self.erro_tolerado):\n",
    "                #print('erro final: ', self.erro)\n",
    "                treinada = True\n",
    "            else:\n",
    "                self.ciclos += 1\n",
    "                \n",
    "        return list(range(0, self.ciclos+1)), erros\n",
    "    \n",
    "    def operacao(self, conjunto_testes):\n",
    "        saidas_mlp = []\n",
    "        for entrada_i in conjunto_testes:\n",
    "            zin = entrada_i * self.pesos_ini_inter + self.bias_intermediario\n",
    "\n",
    "            z = []\n",
    "            for lista in zin:\n",
    "                aux = []\n",
    "                for zini in lista:\n",
    "                    aux.append(self.__f_ativacao(zini))\n",
    "\n",
    "                z.append(aux)\n",
    "                \n",
    "            z = np.array(z)\n",
    "\n",
    "            yin = z @ self.pesos_inter_saida + self.bias_saida\n",
    "            y = self.__f_ativacao(yin[0])\n",
    "            saidas_mlp.append(y)\n",
    "        return saidas_mlp\n",
    "\n",
    "##### definindo as entradas a partir do arquivo digitostreinamento900.txt #####\n",
    "def get_inputs_from_txt():\n",
    "    inputs = []\n",
    "    file = open('digitos/digitostreinamento900.txt', 'r')\n",
    "    for line in file :\n",
    "        line = line.split(\" \")\n",
    "        ipt = []\n",
    "        for element in line:\n",
    "            if element != \"\":\n",
    "                ipt.append(float(element))\n",
    "        inputs.append(ipt)\n",
    "    file.close()\n",
    "    return np.array(inputs)\n",
    "##############################################\n",
    "\n",
    "def get_targets():\n",
    "    targets_aux = pd.read_csv('targets.csv').values\n",
    "    targets = []\n",
    "    for i in range(10):\n",
    "        for j in range(90):\n",
    "            targets.append(list(targets_aux[i]))\n",
    "        \n",
    "    return np.array(targets)\n",
    "\n",
    "def processar():\n",
    "    conjunto_entradas = get_inputs_from_txt()\n",
    "    targets = get_targets()\n",
    "    #print(\"Conjunto de entradas:\", conjunto_entradas[0])\n",
    "    #print(\"targets: \", targets[889])\n",
    "    mlp = RedeMLP(\n",
    "        conjunto_entradas = conjunto_entradas, \n",
    "        targets = targets, \n",
    "        taxa_aprendizagem = taxa_aprendizagem.value,\n",
    "        parada = parada.value.lower(),\n",
    "        ciclos_max = ciclos.value,\n",
    "        erro_tolerado = erro.value,\n",
    "        qnt_neuronios = qnt_neuronios.value\n",
    "    )\n",
    "    '''\n",
    "    print(\"#########################Parametros iniciais: \")\n",
    "    print(\"Entradas: \", mlp.conjunto_entradas)\n",
    "    print(\"pesos: \", mlp.pesos_ini_inter)\n",
    "    print(\"bias: \", mlp.bias_intermediario)\n",
    "    print(\"pesos saida: \", mlp.pesos_inter_saida)\n",
    "    print(\"bias saida: \", mlp.bias_saida)\n",
    "    '''\n",
    "    #print(\"Entradas: \", mlp.conjunto_entradas)\n",
    "    lista_ciclos, lista_erros = mlp.treinamento()\n",
    "    \n",
    "    #Operação da MLP para o conjunto de entradas (usado no treinamento)\n",
    "    #aproximacao_mlp = mlp.operacao(conjunto_entradas)\n",
    "    \n",
    "    #conjunto_testes = gera_conjunto_entrada(-5, 5, 10000)\n",
    "    #targets_testes = gera_targets(conjunto_testes)\n",
    "    #Operação da MLP para o conjunto de testes (usado no treinamento)\n",
    "    #aproximacao_mlp_testes = mlp.operacao(conjunto_testes)\n",
    "    \n",
    "\n",
    "widgets.interact_manual.opts['manual_name'] = 'Treinar a rede' # muda texto do botao\n",
    "interact_manual(processar); # metodo a executar quando pressionar o botao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### definindo as entradas a partir do arquivo digitostreinamento900.txt #####\n",
    "def get_inputs_from_txt():\n",
    "    inputs = []\n",
    "    file = open('digitos/digitostreinamento900.txt', 'r')\n",
    "    for line in file :\n",
    "        line = line.split(\" \")\n",
    "        ipt = []\n",
    "        for element in line:\n",
    "            if element != \"\":\n",
    "                ipt.append(float(element))\n",
    "        inputs.append(ipt)\n",
    "    return inputs\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "inputs = get_inputs_from_txt()\n",
    "print(len(inputs[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 4 6]]\n"
     ]
    }
   ],
   "source": [
    "t1 = np.matrix(np.array([[3,2,3]]))\n",
    "t2 = np.matrix(np.array([2,2,2]))\n",
    "print(np.multiply(t1,t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
