{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Multilayer Perceptron para reconhecimento de padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Taxa de aprendizagem:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f270d4081e4d82a2c09e4ef052353e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.01, continuous_update=False, max=1.0, min=0.01, readout_format='.3f', step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantidade de neurônios da camada intermediária:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a346e486382d4c8a8b9a0ddbc6040e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=30, continuous_update=False, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Erro tolerado:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b6a0f0a2ab4c2f91858c58cb3a7a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.06, continuous_update=False, max=1.0, readout_format='.5f', step=0.001, style=SliderStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799d9b48bd824667bc7c7f4bdcd2fa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Treinar a rede', style=ButtonStyle()), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter, LogLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import random\n",
    "from math import cos, tanh\n",
    "from time import sleep\n",
    "\n",
    "from ipywidgets import *\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "########## entradas dos parametros ##########\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "print('\\n\\nTaxa de aprendizagem:')\n",
    "taxa_aprendizagem = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0.01,\n",
    "    max=1,\n",
    "    step=0.01,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.3f',\n",
    ")\n",
    "display(taxa_aprendizagem)\n",
    "\n",
    "print('\\n\\nQuantidade de neurônios da camada intermediária:')\n",
    "qnt_neuronios = widgets.IntSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "display(qnt_neuronios)\n",
    "\n",
    "print('\\n\\nErro tolerado:')\n",
    "erro = widgets.FloatSlider(\n",
    "    value=0.06,min=0,max=1,step=0.001,\n",
    "    continuous_update=False,\n",
    "    readout=True, style=style,\n",
    "    readout_format='.5f',\n",
    ")\n",
    "display(erro)\n",
    "\n",
    "class RedeMLP():\n",
    "    def __init__(self, conjunto_entradas, targets, taxa_aprendizagem, parada, ciclos_max, \n",
    "                 erro_tolerado, qnt_neuronios, **kwargs):\n",
    "        self.numero_entradas = 256 #tamanho da imagem\n",
    "        self.numero_saidas = 16 #0-9\n",
    "        self.conjunto_entradas = np.array(conjunto_entradas)\n",
    "        self.targets = np.array(targets)\n",
    "        self.taxa_aprendizagem = taxa_aprendizagem\n",
    "        self.taxa_aprendizagem_inicial = taxa_aprendizagem\n",
    "        self.ciclos = 0\n",
    "        self.ciclos_max = ciclos_max\n",
    "        self.parada = parada\n",
    "        #Quantidade de neuronios seleciondos para camada intermediária\n",
    "        self.qnt_neuronios_intermediarios = qnt_neuronios\n",
    "        self.erro_tolerado = erro_tolerado\n",
    "        #Pesos das ligações entre as camadas inicial e intermediária; intermediária e saída\n",
    "        self.pesos_ini_inter, self.pesos_inter_saida = self.__inicializa_pesos()\n",
    "        #Iniciliza os bias da camada intermediária\n",
    "        self.bias_intermediario = np.asmatrix(np.array([random.uniform(-0.5,0.5) for saida in range(qnt_neuronios)]))\n",
    "        #Inicializa o bias da camada de saida\n",
    "        self.bias_saida = np.asmatrix(np.array([random.uniform(-0.5,0.5) for i in range(self.numero_saidas)]))\n",
    "        self.erro = 0\n",
    "        \n",
    "    def set_pesos_ini_inter(self, pesos):\n",
    "        self.pesos_ini_inter = pesos\n",
    "        \n",
    "    def set_pesos_inter_saida(self, pesos):\n",
    "        self.pesos_inter_saida = pesos\n",
    "        \n",
    "    def set_bias_intermediario(self, bias):\n",
    "        self.bias_intermediario = bias\n",
    "        \n",
    "    def set_bias_saida(self, bias):\n",
    "        self.bias_saida = bias\n",
    "        \n",
    "    def __inicializa_pesos(self):\n",
    "        pesos_ini_inter = []\n",
    "        pesos_inter_saida = []\n",
    "        \n",
    "        #mxn = onde m é o número de entradas e n é o número de neurônios da camada intermediária\n",
    "        for i in range(self.numero_entradas):\n",
    "            peso_aux = []\n",
    "            for j in range(self.qnt_neuronios_intermediarios):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_ini_inter.append(peso_aux)\n",
    "        \n",
    "        #nxk onde n é o número de neurônios da camada intermediária e k é o número de saídas\n",
    "        for i in range(self.qnt_neuronios_intermediarios):\n",
    "            peso_aux = []\n",
    "            for i in range(self.numero_saidas):\n",
    "                peso_aux.append(random.uniform(-0.5,0.5))\n",
    "            pesos_inter_saida.append(peso_aux)\n",
    "            \n",
    "        #print(\"Tam peso ini_inter\", len(pesos_ini_inter[0]))\n",
    "        #print(\"Tam peso inter_saida\", len(pesos_inter_saida[0]))\n",
    "        return np.array(pesos_ini_inter), np.array(pesos_inter_saida)\n",
    "    \n",
    "    def __f_ativacao(self, matriz):\n",
    "        #print(\"ZIN\", zin)\n",
    "        out = []\n",
    "        dim = matriz.shape #dimensão da matriz\n",
    "        for i in range(dim[0]):\n",
    "            aux = []\n",
    "            for j in range(dim[1]):\n",
    "                aux.append(tanh(matriz.item(i,j)))\n",
    "            out.append(aux)\n",
    "                \n",
    "        return np.matrix(np.array(out))\n",
    "    \n",
    "    def __calcula_saida__(self, saida):\n",
    "        dists_euclidiana = []\n",
    "        for i in range(10):\n",
    "            calculo = np.sum(np.power(np.power((self.targets[i]-saida),2),0.5))\n",
    "            dists_euclidiana.append(calculo)\n",
    "        menor_valor = np.amin(dists_euclidiana)\n",
    "        id_menor_valor = dists_euclidiana.index(menor_valor)\n",
    "        return np.asmatrix(self.targets[id_menor_valor]);\n",
    "    \n",
    "    def __normaliza_saida__(self, saida):\n",
    "        saida[saida >= 0.5] = 1\n",
    "        saida[saida < 0.5] = 0\n",
    "        return saida\n",
    "        \n",
    "    \n",
    "    def treinamento(self):\n",
    "        treinada = False\n",
    "        erros = []\n",
    "        \n",
    "        pesos_inter_saida_anterior = []\n",
    "        bias_saida_anterior = []\n",
    "        pesos_ini_inter_anterior = []\n",
    "        bias_intermediario_anterior = []\n",
    "        \n",
    "        while not treinada:\n",
    "            i = 0 \n",
    "            self.erro = 0\n",
    "            \n",
    "            for entrada_i in self.conjunto_entradas:\n",
    "                ####################Etapa de Forward#################################\n",
    "                ##############Camada inicial para intermediária\n",
    "                #resultado = 1xn, onde n é o número de neurônios da camada intermediária\n",
    "                \n",
    "                zin = (np.asmatrix(entrada_i) @ self.pesos_ini_inter) + self.bias_intermediario\n",
    "                z = self.__f_ativacao(zin)\n",
    "\n",
    "                ##############Camada intermediária para saída\n",
    "                yin = (z @ self.pesos_inter_saida) + self.bias_saida\n",
    "                y = self.__f_ativacao(yin)\n",
    "                #y = self.__calcula_saida__(y)\n",
    "                #print(\"y\", y)\n",
    "                \n",
    "                \n",
    "                #####################Etapa de backward\n",
    "                #Cálculo do erro\n",
    "                self.erro += 0.5 * np.sum(np.power((self.targets[i] - y), 2))\n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada intermediária para camada de saída\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                #np.multiply para se fazer uma multiplicação item por item\n",
    "                deltak = np.multiply((self.targets[i] - y).T,(1 + y).T)\n",
    "                deltak = np.multiply(deltak, (1 - y).T)\n",
    "                \n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_inter_saida = deltak @ z\n",
    "                delta_pesos_inter_saida = self.taxa_aprendizagem * delta_pesos_inter_saida\n",
    "                \n",
    "                #Parâmetro para correção do bias\n",
    "                delta_bias_saida = np.multiply(self.taxa_aprendizagem, deltak)\n",
    "                \n",
    "                \n",
    "                #########cálculo dos parâmetros para correção dos erros da camada entrada para camada de intermediária\n",
    "                #Calculo dos parâmetros para correção dos pesos e do bias\n",
    "                delta_in = deltak.T @ self.pesos_inter_saida.T\n",
    "                \n",
    "                \n",
    "                deltaj = np.multiply(delta_in, (1+z))\n",
    "                deltaj = np.multiply(deltaj, (1-z))\n",
    "                \n",
    "                #Parâmetro para correção dos pesos\n",
    "                delta_pesos_ini_inter = deltaj.T @ np.asmatrix(entrada_i)\n",
    "                delta_pesos_ini_inter = np.multiply(self.taxa_aprendizagem, delta_pesos_ini_inter)\n",
    "                \n",
    "                delta_bias_intermediario = np.multiply(self.taxa_aprendizagem, deltaj)\n",
    "\n",
    "                if (self.ciclos == 0) and (i == 0):\n",
    "                    pesos_inter_saida_anterior = self.pesos_inter_saida\n",
    "                    bias_saida_anterior = self.bias_saida\n",
    "                    pesos_ini_inter_anterior = self.pesos_ini_inter\n",
    "                    bias_intermediario_anterior = self.bias_intermediario\n",
    "                    #Correção dos pesos da camada intermediária para camada de saída e bias da camada de saída\n",
    "                    self.pesos_inter_saida = self.pesos_inter_saida + delta_pesos_inter_saida.T \n",
    "                    self.bias_saida = self.bias_saida + delta_bias_saida.T\n",
    "                    #Correção dos pesos da camada intermediária para camada de saída e bias da camada de intermediária\n",
    "                    self.pesos_ini_inter = self.pesos_ini_inter + delta_pesos_ini_inter.T\n",
    "                    self.bias_intermediario = self.bias_intermediario + delta_bias_intermediario\n",
    "                else:\n",
    "                    const_momentum = random.uniform(0.15, 0.75)\n",
    "                    termo_momentum = const_momentum * (self.pesos_inter_saida - pesos_inter_saida_anterior)\n",
    "                    pesos_inter_saida_anterior = self.pesos_inter_saida\n",
    "                    self.pesos_inter_saida = self.pesos_inter_saida + delta_pesos_inter_saida.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.bias_saida - bias_saida_anterior)\n",
    "                    bias_saida_anterior = self.bias_saida\n",
    "                    self.bias_saida = self.bias_saida + delta_bias_saida.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.pesos_ini_inter - pesos_ini_inter_anterior)\n",
    "                    pesos_ini_inter_anterior = self.pesos_ini_inter\n",
    "                    self.pesos_ini_inter = self.pesos_ini_inter + delta_pesos_ini_inter.T + termo_momentum\n",
    "                    \n",
    "                    termo_momentum = const_momentum * (self.bias_intermediario - bias_intermediario_anterior)\n",
    "                    bias_intermediario_anterior = self.bias_intermediario\n",
    "                    self.bias_intermediario = self.bias_intermediario + delta_bias_intermediario + termo_momentum\n",
    "                \n",
    "                i+=1\n",
    "\n",
    "            self.erro = (1/900)*self.erro\n",
    "            erros.append(self.erro)\n",
    "            print('erro', self.erro)\n",
    "            if (self.parada == 'ciclos' and self.ciclos >= self.ciclos_max) \\\n",
    "                or (self.parada == 'erro' and self.erro <= self.erro_tolerado):\n",
    "                #print('erro final: ', self.erro)\n",
    "                treinada = True\n",
    "            else:\n",
    "                self.ciclos += 1\n",
    "                \n",
    "        return list(range(0, self.ciclos+1)), erros\n",
    "    \n",
    "    def operacao(self, conjunto_testes, targets_testes):\n",
    "        acertos = 0\n",
    "        i = 0\n",
    "        for entrada_i in conjunto_testes:\n",
    "            zin = (np.asmatrix(entrada_i) @ self.pesos_ini_inter) + self.bias_intermediario\n",
    "            z = self.__f_ativacao(zin)\n",
    "\n",
    "            yin = (z @ self.pesos_inter_saida) + self.bias_saida\n",
    "            y = self.__f_ativacao(yin)\n",
    "            #y = self.__normaliza_saida__(y)\n",
    "            y = self.__calcula_saida__(y)\n",
    "            if(np.array_equal(np.asmatrix(y), np.asmatrix(targets_testes[i]))):\n",
    "                acertos += 1\n",
    "            i+=1\n",
    "\n",
    "        return acertos\n",
    "\n",
    "##### definindo as entradas a partir do arquivo digitostreinamento900.txt #####\n",
    "def get_inputs_from_txt():\n",
    "    inputs = []\n",
    "    file = open('digitos/digitostreinamento900.txt', 'r')\n",
    "    for line in file :\n",
    "        line = line.split(\" \")\n",
    "        ipt = []\n",
    "        for element in line:\n",
    "            if element != \"\":\n",
    "                ipt.append(float(element))\n",
    "        inputs.append(ipt)\n",
    "    file.close()\n",
    "    return np.array(inputs)\n",
    "##############################################\n",
    "\n",
    "\n",
    "def get_inputs_test_from_txt():\n",
    "    path_to_folder = 'C:\\\\Users\\\\Marco Antônio\\\\Documents\\\\IA\\\\Trabalhos\\\\trabalhos-ia\\\\trab9\\\\teste'\n",
    "    inputs = []\n",
    "    for i in os.listdir(path_to_folder):\n",
    "        file = open(path_to_folder + '\\\\' + i, 'r')\n",
    "        for line in file :\n",
    "            line = line.split(\" \")\n",
    "            ipt = []\n",
    "            for element in line:\n",
    "                if element != \"\":\n",
    "                    ipt.append(float(element))\n",
    "            inputs.append(ipt)\n",
    "        file.close()\n",
    "    return np.array(inputs)\n",
    "\n",
    "def get_obvs(k, m):\n",
    "    semente = np.array([[1]])\n",
    "    obvs = []\n",
    "    for i in range(k):\n",
    "        aux_obv = []\n",
    "        for j in range(2**i):\n",
    "            comb1 = np.array(np.concatenate((semente[j], semente[j])))\n",
    "            comb2 = np.array(np.concatenate((semente[j], -1*semente[j])))\n",
    "            aux_obv.append(np.array(comb1))\n",
    "            aux_obv.append(np.array(comb2))\n",
    "        semente = aux_obv\n",
    "        obvs = aux_obv\n",
    "        \n",
    "    targets = []\n",
    "    for i in range(90):\n",
    "        for j in range(10):\n",
    "            targets.append(obvs[j])\n",
    "        \n",
    "    return np.array(targets)\n",
    "\n",
    "def get_obvs_teste(k, m):\n",
    "    semente = np.array([[1]])\n",
    "    obvs = []\n",
    "    for i in range(k):\n",
    "        aux_obv = []\n",
    "        for j in range(2**i):\n",
    "            comb1 = np.array(np.concatenate((semente[j], semente[j])))\n",
    "            comb2 = np.array(np.concatenate((semente[j], -1*semente[j])))\n",
    "            aux_obv.append(np.array(comb1))\n",
    "            aux_obv.append(np.array(comb2))\n",
    "        semente = aux_obv\n",
    "        obvs = aux_obv\n",
    "        \n",
    "    targets = []\n",
    "    for i in range(10):\n",
    "        for j in range(45):\n",
    "            targets.append(obvs[i])\n",
    "        \n",
    "    return np.array(targets)\n",
    "\n",
    "def get_targets():\n",
    "    targets_aux = pd.read_csv('targets.csv').values\n",
    "    targets = []\n",
    "    for i in range(90):\n",
    "        for j in range(10):\n",
    "            targets.append(list(targets_aux[j]))\n",
    "    return np.array(targets)\n",
    "\n",
    "def get_targets_teste():\n",
    "    targets_aux = pd.read_csv('targets.csv').values\n",
    "    targets = []\n",
    "    for i in range(10):\n",
    "        for j in range(45):\n",
    "            targets.append(list(targets_aux[i]))\n",
    "    return np.array(targets)\n",
    "\n",
    "def processar():\n",
    "    conjunto_entradas = get_inputs_from_txt()\n",
    "    #targets = get_targets()\n",
    "    targets = get_obvs(4,1)\n",
    "    mlp = RedeMLP(\n",
    "        conjunto_entradas = conjunto_entradas, \n",
    "        targets = targets, \n",
    "        taxa_aprendizagem = taxa_aprendizagem.value,\n",
    "        parada = 'erro',\n",
    "        ciclos_max = 0,\n",
    "        erro_tolerado = erro.value,\n",
    "        qnt_neuronios = qnt_neuronios.value\n",
    "    )\n",
    "\n",
    "    #print(\"Entradas: \", mlp.conjunto_entradas)\n",
    "    lista_ciclos, lista_erros = mlp.treinamento() \n",
    "    conjunto_testes = get_inputs_test_from_txt()\n",
    "    targets_testes = get_obvs_teste(4, 1)\n",
    "    #targets_testes = get_targets_teste()\n",
    "    acertos = mlp.operacao(conjunto_testes, targets_testes)\n",
    "    np.savetxt('vij.txt',mlp.pesos_ini_inter, delimiter=\",\")\n",
    "    np.savetxt('v0j.txt',mlp.bias_intermediario, delimiter=\",\")\n",
    "    np.savetxt('wij.txt',mlp.pesos_inter_saida, delimiter=\",\")\n",
    "    np.savetxt('w0j.txt',mlp.bias_saida, delimiter=\",\")\n",
    "    print('acertos:', acertos)\n",
    "    print('ciclos:', mlp.ciclos)\n",
    "    print('taxa_acertos: {:f}'.format((acertos/450) *100))\n",
    "\n",
    "    \n",
    "    \n",
    "def read_matrix_in_txt(path):\n",
    "    file = open(path)\n",
    "    matrix = []\n",
    "    for line in file:\n",
    "        matrix.append(list(map(float, line.split(','))))\n",
    "    return np.asmatrix(matrix)\n",
    "    \n",
    "def executar_mlp():\n",
    "    conjunto_testes = get_inputs_test_from_txt()\n",
    "    targets_testes = get_obvs_teste(4, 1)\n",
    "    mlp = RedeMLP(\n",
    "        conjunto_entradas = conjunto_testes, \n",
    "        targets = targets_testes, \n",
    "        taxa_aprendizagem = 0.01,\n",
    "        parada = 'erro',\n",
    "        ciclos_max = 0,\n",
    "        erro_tolerado = 0,\n",
    "        qnt_neuronios = 30\n",
    "    )\n",
    "    \n",
    "    v0j = read_matrix_in_txt('v0j.txt')\n",
    "    vij = read_matrix_in_txt('vij.txt')\n",
    "    w0j = read_matrix_in_txt('w0j.txt')\n",
    "    wij = read_matrix_in_txt('wij.txt')\n",
    "    \n",
    "    mlp.set_pesos_ini_inter(vij)\n",
    "    mlp.set_bias_intermediario(v0j)\n",
    "    mlp.set_pesos_inter_saida(wij)\n",
    "    mlp.set_bias_saida(w0j)\n",
    "    print(mlp.bias_intermediario)\n",
    "        \n",
    "    acertos = mlp.operacao(conjunto_testes, targets_testes)\n",
    "    print(\"Acertos da rede: \", acertos)\n",
    "    print(\"Taxa de acerto: \", acertos * 100/450)\n",
    "    \n",
    "    \n",
    "widgets.interact_manual.opts['manual_name'] = 'Treinar a rede' # muda texto do botao\n",
    "interact_manual(processar); # metodo a executar quando pressionar o botao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
